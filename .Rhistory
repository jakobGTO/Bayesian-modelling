b = slider(1, 100, step=1, initial = 44, label = "The hyperparameter b in Beta(a,b) prior"),
n = slider(1, 1000, step=1, initial = 1000, label = "The number of trials, n"),
p = slider(0, 1, step=0.01, initial = 0.60, label = "Success proportion in the sample")
)
BetaPriorPostPlot <- function(a,b,n,p){
xGrid <- seq(0.001, 0.999, by=0.001)
normalizedLikelihood = dbeta(xGrid, n*p+1, n*(1-p)+1)
prior = dbeta(xGrid, a, b)
posterior = dbeta(xGrid, a+n*p, b+n*(1-p))
maxDensity <- max(normalizedLikelihood, prior, posterior) # Use to make the y-axis high enough
plot(xGrid, normalizedLikelihood, type = 'l', lwd = 3, col = "blue", xlim <- c(0,1), ylim <- c(0, maxDensity), xlab = "theta",
ylab = 'Density', main = 'Bernoulli model - Beta(a,b) prior')
lines(xGrid, posterior, lwd = 3, col = "red")
lines(xGrid, prior, lwd = 3, col = "green")
legend(x = 0.01, y = maxDensity*0.95, legend = c("Likelihood (normalized)", "Prior", "Posterior"), col = c("blue","green","red"), lwd = c(3,3,3), cex = 0.5)
}
manipulate(
BetaPriorPostPlot(a,b,n,p),
a = slider(1, 100, step=1, initial = 54, label = "The hyperparameter a in Beta(a,b) prior"),
b = slider(1, 100, step=1, initial = 44, label = "The hyperparameter b in Beta(a,b) prior"),
n = slider(1, 1000, step=1, initial = 1000, label = "The number of trials, n"),
p = slider(0, 1, step=0.01, initial = 0.60, label = "Success proportion in the sample")
)
BetaPriorPostPlot <- function(a,b,n,p){
xGrid <- seq(0.001, 0.999, by=0.001)
normalizedLikelihood = dbeta(xGrid, n*p+1, n*(1-p)+1)
prior = dbeta(xGrid, a, b)
posterior = dbeta(xGrid, a+n*p, b+n*(1-p))
maxDensity <- max(normalizedLikelihood, prior, posterior) # Use to make the y-axis high enough
plot(xGrid, normalizedLikelihood, type = 'l', lwd = 3, col = "blue", xlim <- c(0,1), ylim <- c(0, maxDensity), xlab = "theta",
ylab = 'Density', main = 'Bernoulli model - Beta(a,b) prior')
lines(xGrid, posterior, lwd = 3, col = "red")
lines(xGrid, prior, lwd = 3, col = "green")
legend(x = 0.01, y = maxDensity*0.95, legend = c("Likelihood (normalized)", "Prior", "Posterior"), col = c("blue","green","red"), lwd = c(3,3,3), cex = 0.5)
}
manipulate(
BetaPriorPostPlot(a,b,n,p),
a = slider(1, 100, step=1, initial = 54, label = "The hyperparameter a in Beta(a,b) prior"),
b = slider(1, 100, step=1, initial = 44, label = "The hyperparameter b in Beta(a,b) prior"),
n = slider(1, 1000, step=1, initial = 1000, label = "The number of trials, n"),
p = slider(0, 1, step=0.01, initial = 0.60, label = "Success proportion in the sample")
)
BetaPriorPostPlot <- function(a,b,n,p){
xGrid <- seq(0.001, 0.999, by=0.001)
normalizedLikelihood = dbeta(xGrid, n*p+1, n*(1-p)+1)
prior = dbeta(xGrid, a, b)
posterior = dbeta(xGrid, a+n*p, b+n*(1-p))
maxDensity <- max(normalizedLikelihood, prior, posterior) # Use to make the y-axis high enough
plot(xGrid, normalizedLikelihood, type = 'l', lwd = 3, col = "blue", xlim <- c(0,1), ylim <- c(0, maxDensity), xlab = "theta",
ylab = 'Density', main = 'Bernoulli model - Beta(a,b) prior')
lines(xGrid, posterior, lwd = 3, col = "red")
lines(xGrid, prior, lwd = 3, col = "green")
legend(x = 0.01, y = maxDensity*0.95, legend = c("Likelihood (normalized)", "Prior", "Posterior"), col = c("blue","green","red"), lwd = c(3,3,3), cex = 0.5)
}
manipulate(
BetaPriorPostPlot(a,b,n,p),
a = slider(1, 150, step=1, initial = 54, label = "The hyperparameter a in Beta(a,b) prior"),
b = slider(1, 150, step=1, initial = 44, label = "The hyperparameter b in Beta(a,b) prior"),
n = slider(1, 2000, step=1, initial = 1000, label = "The number of trials, n"),
p = slider(0, 1, step=0.01, initial = 0.60, label = "Success proportion in the sample")
)
prior = dbeta(xGrid, a, b)
posterior = dbeta(xGrid, a+n*p, b+n*(1-p))
BetaPriorPostPlot <- function(a,b,n,p){
xGrid <- seq(0.001, 0.999, by=0.001)
normalizedLikelihood = dbeta(xGrid, n*p+1, n*(1-p)+1)
prior = dbeta(xGrid, a, b)
posterior = dbeta(xGrid, a+n*p, b+n*(1-p))
maxDensity <- max(normalizedLikelihood, prior, posterior) # Use to make the y-axis high enough
plot(xGrid, normalizedLikelihood, type = 'l', lwd = 3, col = "blue", xlim <- c(0,1), ylim <- c(0, maxDensity), xlab = "theta",
ylab = 'Density', main = 'Bernoulli model - Beta(a,b) prior')
lines(xGrid, posterior, lwd = 3, col = "red")
lines(xGrid, prior, lwd = 3, col = "green")
legend(x = 0.01, y = maxDensity*0.95, legend = c("Likelihood (normalized)", "Prior", "Posterior"), col = c("blue","green","red"), lwd = c(3,3,3), cex = 0.5)
}
manipulate(
BetaPriorPostPlot(a,b,n,p),
a = slider(1, 150, step=1, initial = 54, label = "The hyperparameter a in Beta(a,b) prior"),
b = slider(1, 150, step=1, initial = 44, label = "The hyperparameter b in Beta(a,b) prior"),
n = slider(1, 2000, step=1, initial = 1000, label = "The number of trials, n"),
p = slider(0, 1, step=0.01, initial = 0.60, label = "Success proportion in the sample")
)
BetaPriorPostPlot <- function(a,b,n,p){
xGrid <- seq(0.001, 0.999, by=0.001)
normalizedLikelihood = dbeta(xGrid, n*p+1, n*(1-p)+1)
prior = dbeta(xGrid, a, b)
posterior = dbeta(xGrid, a+n*p, b+n*(1-p))
maxDensity <- max(normalizedLikelihood, prior, posterior) # Use to make the y-axis high enough
plot(xGrid, normalizedLikelihood, type = 'l', lwd = 3, col = "blue", xlim <- c(0,1), ylim <- c(0, maxDensity), xlab = "theta",
ylab = 'Density', main = 'Bernoulli model - Beta(a,b) prior')
lines(xGrid, posterior, lwd = 3, col = "red")
lines(xGrid, prior, lwd = 3, col = "green")
legend(x = 0.01, y = maxDensity*0.95, legend = c("Likelihood (normalized)", "Prior", "Posterior"), col = c("blue","green","red"), lwd = c(3,3,3), cex = 0.5)
}
manipulate(
BetaPriorPostPlot(a,b,n,p),
a = slider(1, 150, step=1, initial = 54, label = "The hyperparameter a in Beta(a,b) prior"),
b = slider(1, 150, step=1, initial = 44, label = "The hyperparameter b in Beta(a,b) prior"),
n = slider(1, 2000, step=1, initial = 1000, label = "The number of trials, n"),
p = slider(0, 1, step=0.01, initial = 0.60, label = "Success proportion in the sample")
)
mean(samples)
sd(samples)
#e)
posterior_PI <- rbeta(1e4,alpha,beta)
posterior_PI
#e)
posterior_PI <- rbeta(1e4,alpha,beta,ncp = 0)
PI( posterior_PI , prob=0.5 )
PI( posterior_PI , prob=0.909 )
PI( posterior_PI , prob=0.90 )
PI( posterior_PI , prob=0.8)
PI( posterior_PI , prob=0.81)
PI( posterior_PI , prob=0.82)
PI( posterior_PI , prob=0.8005)
PI( posterior_PI , prob=0.805 )
PI( posterior_PI , prob=0.81 )
PI( posterior_PI , prob=0.8105 )
PI( posterior_PI , prob=0.81 )
PI( posterior_PI , prob=0.815 )
PI( posterior_PI , prob=0.909 )
# R code 3.3
samples_grid <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # dra v?rden fr?n posteriorn
mean(samples_grid)
sd(samples_grid)
PI( posterior_PI , prob=0.909 )
PI( posterior_PI , prob=0.91 )
PI( posterior_PI , prob=0.905 )
PI( posterior_PI , prob=0.905 )
PI( posterior_PI , prob=0.99 )
PI( posterior_PI , prob=0.905 )
PI( posterior_PI , prob=0.909 )
1e5
1e5
1e5
samples_grid
PI( posterior_PI , prob=0.909 )
PI( posterior_PI , prob=0.91 )
PI( posterior_PI , prob=0.05 )
PI( posterior_PI , prob=0.905 )
PI( posterior_PI , prob=0.909 )
samples_grid
samples_grid / 1 - samples_grid
odds <- samples_grid / 1 - samples_grid
odds
samples_grid
odds <- samples_grid / (1 + samples_grid)
odds
hist(odds)
odds <- samples_grid / (1 - samples_grid)
hist(odds)
dens(odds)
odds <- samplesQ / (1 - samplesQ)
odds
odds <- samplesQ / (1 - samplesQ)
dens(odds)
odds <- samplesQ / (1 - samplesQ)
dens(odds)
data(chickwts)
soybeans_index <- chickwts$feed == "soybean"
meatmeal_index <- chickwts$feed == "meatmeal"
soybean_data <- chickwts[soybeans_index,1:2]
meatmeal_data <- chickwts[meatmeal_index,1:2]
ejsoy_ejmeat <-chickwts[!soybeans_index&!meatmeal_index,1:2]
#a)
Stavv <- sd(soybean_data[,1])
PriorMu <- mean(ejsoy_ejmeat[,1])
PriorStavv <- sd(ejsoy_ejmeat[,1])
flist <- alist(
weight ~ dnorm(mu, Stavv) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu , PriorStavv ) # normalf?rdelad prior
)
resNormal <- map(flist, data=soybean_data)
precis(resNormal)
#b)
Stavv_b <- sd(meatmeal_data[,1])
PriorMu_b <- mean(ejsoy_ejmeat[,1])
PriorStavv_b <- sd(ejsoy_ejmeat[,1])
flist_b <- alist(
weight ~ dnorm(mu, Stavv_b) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu_b , PriorStavv_b ) # normalf?rdelad prior
)
resNormal_b <- map(flist_b, data=meatmeal_data)
precis(resNormal_b)
samples_2b <- rnorm(1e4, 276.2, 19.09)
dens(samples_2b, type="l",col="black")
samples_2b <- rnorm(1e4, 276.2, 19.09)
dens(samples_2b, type="l",col="black")
dens(samples_2b, type="l",col="red",add=TRUE)
#Plotta a och b i samma
#LÃ¤gre medelvÃ¤rdes vikt och hÃ¶gre varians i meatmeal kycklingar Ã¤n soybean kycklingar
dens(samples_2a, type="l",col="black")
dens(samples_2b, type="l",col="red",add=TRUE)
#a)
Stavv <- sd(soybean_data[,1])
PriorMu <- mean(ejsoy_ejmeat[,1])
PriorStavv <- sd(ejsoy_ejmeat[,1])
flist <- alist(
weight ~ dnorm(mu, Stavv) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu , PriorStavv ) # normalf?rdelad prior
)
resNormal <- map(flist, data=soybean_data)
precis(resNormal)
samples_2a <- rnorm(1e4, 246.85, 14.27)
dens(samples_2a, type="l",col="black")
soybean_data
#a)
Stavv <- sd(soybean_data[,1])
PriorMu <- mean(ejsoy_ejmeat[,1])
PriorStavv <- sd(ejsoy_ejmeat[,1])
flist <- alist(
weight ~ dnorm(mu, Stavv) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu , PriorStavv ) # normalf?rdelad prior
)
resNormal <- map(flist, data=soybean_data)
precis(resNormal)
samples_2a <- rnorm(1e4, 246.85, 14.27)
dens(samples_2a, type="l",col="black")
#b)
Stavv_b <- sd(meatmeal_data[,1])
PriorMu_b <- mean(ejsoy_ejmeat[,1])
PriorStavv_b <- sd(ejsoy_ejmeat[,1])
flist_b <- alist(
weight ~ dnorm(mu, Stavv_b) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu_b , PriorStavv_b ) # normalf?rdelad prior
)
resNormal_b <- map(flist_b, data=meatmeal_data)
precis(resNormal_b)
samples_2b <- rnorm(1e4, 276.2, 19.09)
dens(samples_2b, type="l",col="black")
#Plotta a och b i samma
#LÃ¤gre medelvÃ¤rdes vikt och hÃ¶gre varians i meatmeal kycklingar Ã¤n soybean kycklingar
dens(samples_2a, type="l",col="black")
dens(samples_2b, type="l",col="red",add=TRUE)
samples_2a - samples_2b
posterior_diff <- samples_2a - samples_2b
dens(posterior_diff)
mean(posteriof_diff)
mean(posterior_diff)
posterior_diff <- samples_2b - samples_2a
dens(posterior_diff)
sum( posterior_diff > 0) / 1e4
sum( samples_2b > samples_2a) / 1e4
sum( samples_2b > samples_2a) / 1e4
posterior_diff <- samples_2b - samples_2a
dens(posterior_diff)
sum( samples_2b > samples_2a) / 1e4
valdata <- read.csv2("C:/Users/Jakob/Desktop/Bayesian statistics/valdata.csv")
val_andel_mp <- valdata[1:12,10]/100
alpha <- 8.389154
beta <- 112.6174
prior <- rbeta(n = 1e4, alpha,beta, ncp=0)
dens(prior)
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black")
dens(prior,col="red",add=TRUE)
mean(posterior)
mean(prior)
dens(posterior,col="black",main = "asd")
dens(prior,main = "PriorfÃ¶rdelning beta(8.39,112.62)")
valdata <- read.csv2("C:/Users/Jakob/Desktop/Bayesian statistics/valdata.csv")
val_andel_mp <- valdata[1:12,10]/100
alpha <- 8.389154
beta <- 112.6174
prior <- rbeta(n = 1e4, alpha,beta, ncp=0)
dens(prior,main = "PriorfÃ¶rdelning beta(8.39,112.62)")
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black")
dens(prior,col="red",add=TRUE)
dens(prior,col="red",add=TRUE, main = "Posterior- (Svart) och PriorfÃ¶rdelning (RÃ¶d)")
dens(posterior,col="black")
dens(prior,col="red",add=TRUE, main = "Posterior- (Svart) och PriorfÃ¶rdelning (RÃ¶d)")
dens(posterior,col="black", main = "Posterior- (Svart) och PriorfÃ¶rdelning (RÃ¶d)")
dens(prior,col="red",add=TRUE)
p_grid <- seq( from=0 , to=1 , length.out=1000 ) # grid av v?rden
# Allm?n Beta prior, BW, se f?rel?sningsslides
prior <- dbeta(p_grid, alpha, beta, ncp = 0, log = FALSE)
likelihood <- dbinom( round(sumxi) , size=n , prob=p_grid )
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior <- posterior / sum(posterior) # g?r posteriorn till en t?thet
# R code 3.3
samples_grid <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # dra v?rden fr?n posteriorn
# R code 3.4
plot( samples_grid ) # plotta v?rdena
dens(samples_grid)
dens(samples_grid, main = "PosteriorfÃ¶rdelning med grid approximation")
# R code 2.6, tag fram posteriorf?rdelningen med kvadratisk approximation
KA <- map(
alist(
w ~ dbinom(1612,p) , # binomial likelihood
p ~ dbeta(8.389154,112.6174) # beta prior
) ,
data=list(w=77) )
# display summary of quadratic approximation
precis( KA , digits=5)
# Plotta kvadratiska approximationen mot grid approximationen. Anv?nd medelv?rde och st.avv. fr?n funktion precis.
samplesQ <- rnorm(1e4,0.04875,0.00517)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black")
dens(samplesQ,type="l",col="red",add=TRUE)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- (svart) och kvadratisk (rÃ¶d) approximation")
dens(samplesQ,type="l",col="red",add=TRUE)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk")
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation")
dens(samplesQ,type="l",col="red",add=TRUE)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation",sub="Grid (svart), Kvadrat (rÃ¶d)")
dens(samplesQ,type="l",col="red",add=TRUE)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation")
mtext(side=3, line=2, at=-0.07, adj=0, cex=0.7, "mysubtitle")
dens(samplesQ,type="l",col="red",add=TRUE)
p_grid <- seq( from=0 , to=1 , length.out=1000 ) # grid av v?rden
# Allm?n Beta prior, BW, se f?rel?sningsslides
prior <- dbeta(p_grid, alpha, beta, ncp = 0, log = FALSE)
likelihood <- dbinom( round(sumxi) , size=n , prob=p_grid )
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior <- posterior / sum(posterior) # g?r posteriorn till en t?thet
# R code 3.3
samples_grid <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # dra v?rden fr?n posteriorn
# R code 3.4
plot( samples_grid ) # plotta v?rdena
dens(samples_grid, main = "PosteriorfÃ¶rdelning med grid approximation")
# R code 2.6, tag fram posteriorf?rdelningen med kvadratisk approximation
KA <- map(
alist(
w ~ dbinom(1612,p) , # binomial likelihood
p ~ dbeta(8.389154,112.6174) # beta prior
) ,
data=list(w=77) )
# display summary of quadratic approximation
precis( KA , digits=5)
# Plotta kvadratiska approximationen mot grid approximationen. Anv?nd medelv?rde och st.avv. fr?n funktion precis.
samplesQ <- rnorm(1e4,0.04875,0.00517)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation")
mtext(side=3, line=2, at=-0.07, adj=0, cex=0.7, "mysubtitle")
dens(samplesQ,type="l",col="red",add=TRUE)
plot(samples)
mtext(side=3, line=2, at=-0.07, adj=0, cex=0.7, "mysubtitle")
mytitle = "I want main title NOT bold and left aligned"
mysubtitle = "Sub title should be under the main title left aligned"
mtext(side=3, line=3, at=-0.07, adj=0, cex=1, mytitle)
mtext(side=3, line=2, at=-0.07, adj=0, cex=0.7, mysubtitle)
plot(samples)
mytitle = "I want main title NOT bold and left aligned"
mysubtitle = "Sub title should be under the main title left aligned"
mtext(side=3, line=3, at=-0.07, adj=0, cex=1, mytitle)
mtext(side=3, line=2, at=-0.07, adj=0, cex=0.7, mysubtitle)
dens(samplesQ,type="l",col="red",add=TRUE)
# Plotta kvadratiska approximationen mot grid approximationen. Anv?nd medelv?rde och st.avv. fr?n funktion precis.
samplesQ <- rnorm(1e4,0.04875,0.00517)
#Black = gridapprox, Red = kvadrat approx
dens(samplesQ,type="l",col="red",add=TRUE)
#Black = gridapprox, Red = kvadrat approx
dens(samplesQ,type="l",col="red",add=TRUE)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation")
dens(samplesQ,type="l",col="red",add=TRUE)
ðŸ˜Ž
legend(8, 240, legend = c("nBideBay", "rpois"), fill=c(rgb(0.5, 0.5, 0.5, 1/4), rgb(0, 0.5, 0.5, 1/4)), cex = 0.8)
dens(samplesQ,type="l",col="red",add=TRUE)
legend(8, 240, legend = c("nBideBay", "rpois"), fill=c(rgb(0.5, 0.5, 0.5, 1/4), rgb(0, 0.5, 0.5, 1/4)), cex = 0.8)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation")
legend(8, 240, legend = c("nBideBay", "rpois"), fill=c(rgb(0.5, 0.5, 0.5, 1/4), rgb(0, 0.5, 0.5, 1/4)), cex = 0.8)
dens(samplesQ,type="l",col="red",add=TRUE)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation")
dens(samplesQ,type="l",col="red",add=TRUE)
#f)
posterior_PI <- rbeta(1e4,alpha,beta,ncp = 0)
PI( posterior_PI , prob=0.909 )
odds <- samplesQ / (1 - samplesQ)
dens(odds)
data(chickwts)
soybeans_index <- chickwts$feed == "soybean"
meatmeal_index <- chickwts$feed == "meatmeal"
soybean_data <- chickwts[soybeans_index,1:2]
meatmeal_data <- chickwts[meatmeal_index,1:2]
ejsoy_ejmeat <-chickwts[!soybeans_index&!meatmeal_index,1:2]
#a)
Stavv <- sd(soybean_data[,1])
PriorMu <- mean(ejsoy_ejmeat[,1])
PriorStavv <- sd(ejsoy_ejmeat[,1])
flist <- alist(
weight ~ dnorm(mu, Stavv) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu , PriorStavv ) # normalf?rdelad prior
)
resNormal <- map(flist, data=soybean_data)
precis(resNormal)
samples_2a <- rnorm(1e4, 246.85, 14.27)
dens(samples_2a, type="l",col="black")
#b)
Stavv_b <- sd(meatmeal_data[,1])
PriorMu_b <- mean(ejsoy_ejmeat[,1])
PriorStavv_b <- sd(ejsoy_ejmeat[,1])
flist_b <- alist(
weight ~ dnorm(mu, Stavv_b) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu_b , PriorStavv_b ) # normalf?rdelad prior
)
dens(samples_2a, type="l",col="black", main = "FÃ¶rdelning av vikten pÃ¥ kyckling som Ã¤tit soybeans")
samples_2a <- rnorm(1e4, 246.85, 14.27)
dens(samples_2a, type="l",col="black", main = "FÃ¶rdelning av vikten pÃ¥ kyckling som Ã¤tit soybeans")
#b)
Stavv_b <- sd(meatmeal_data[,1])
PriorMu_b <- mean(ejsoy_ejmeat[,1])
PriorStavv_b <- sd(ejsoy_ejmeat[,1])
flist_b <- alist(
weight ~ dnorm(mu, Stavv_b) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu_b , PriorStavv_b ) # normalf?rdelad prior
)
resNormal_b <- map(flist_b, data=meatmeal_data)
precis(resNormal_b)
samples_2b <- rnorm(1e4, 276.2, 19.09)
dens(samples_2b, type="l",col="black")
#Plotta a och b i samma
#LÃ¤gre medelvÃ¤rdes vikt och hÃ¶gre varians i meatmeal kycklingar Ã¤n soybean kycklingar
dens(samples_2a, type="l",col="black")
dens(samples_2b, type="l",col="red",add=TRUE)
legend(200, 0.025, legend = c("nBideBay", "rpois"), fill=c(rgb(0.5, 0.5, 0.5, 1/4), rgb(0, 0.5, 0.5, 1/4)), cex = 0.8)
legend(200, 0.025, legend = c("Soybeans", "Meatmeal"), fill=c(rgb(0.5, 0.5, 0.5, 1/4), rgb(0, 0.5, 0.5, 1/4)), cex = 0.8)
legend(300, 0.025, legend = c("Soybeans", "Meatmeal"), fill=c(rgb(0.5, 0.5, 0.5, 1/4), rgb(0, 0.5, 0.5, 1/4)), cex = 0.8)
#Plotta a och b i samma
#LÃ¤gre medelvÃ¤rdes vikt och hÃ¶gre varians i meatmeal kycklingar Ã¤n soybean kycklingar
dens(samples_2a, type="l",col="black")
dens(samples_2b, type="l",col="red",add=TRUE)
legend(280, 0.025, legend = c("Soybeans", "Meatmeal"), fill=c(rgb(0.5, 0.5, 0.5, 1/4), rgb(0, 0.5, 0.5, 1/4)), cex = 0.8)
#Plotta a och b i samma
#LÃ¤gre medelvÃ¤rdes vikt och hÃ¶gre varians i meatmeal kycklingar Ã¤n soybean kycklingar
dens(samples_2a, type="l",col="black")
dens(samples_2b, type="l",col="red",add=TRUE)
legend(280, 0.028, legend = c("Soybeans", "Meatmeal"), fill=c(rgb(0.5, 0.5, 0.5, 1/4), rgb(0, 0.5, 0.5, 1/4)), cex = 0.8)
legend(280, 0.028, legend = c("Soybeans", "Meatmeal"), fill=c("black", "red")), cex = 0.8)
legend(280, 0.028, legend = c("Soybeans", "Meatmeal"), fill=c("black", "red"), cex = 0.8)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation")
dens(samplesQ,type="l",col="red",add=TRUE)
legend(280, 0.028, legend = c("Soybeans", "Meatmeal"), fill=c("black", "red"), cex = 0.8)
legend(0.06, 80, legend = c("Soybeans", "Meatmeal"), fill=c("black", "red"), cex = 0.8)
#Black = gridapprox, Red = kvadrat approx
dens(samples,type="l",col="black", main = "PosteriorfÃ¶rdelning med grid- och kvadratisk approximation")
dens(samplesQ,type="l",col="red",add=TRUE)
legend(0.06, 80, legend = c("Gridapproximation", "Kvadradapproximation"), fill=c("black", "red"), cex = 0.8)
dens(posterior,col="black", main = "Posterior- (Svart) och PriorfÃ¶rdelning (RÃ¶d)")
dens(prior,col="red",add=TRUE)
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- (Svart) och PriorfÃ¶rdelning (RÃ¶d)")
dens(prior,col="red",add=TRUE)
dens(prior,col="red",add=TRUE)
valdata <- read.csv2("C:/Users/Jakob/Desktop/Bayesian statistics/valdata.csv")
val_andel_mp <- valdata[1:12,10]/100
alpha <- 8.389154
beta <- 112.6174
prior <- rbeta(n = 1e4, alpha,beta, ncp=0)
dens(prior,main = "PriorfÃ¶rdelning beta(8.39,112.62)")
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- (Svart) och PriorfÃ¶rdelning (RÃ¶d)")
dens(prior,col="red",add=TRUE)
legend(280, 0.028, legend = c("Soybeans", "Meatmeal"), fill=c("black", "red"), cex = 0.8)
legend(0.06, 80, legend = c("Soybeans", "Meatmeal"), fill=c("black", "red"), cex = 0.8)
dens(posterior,col="black", main = "Posterior- och PriorfÃ¶rdelning")
dens(prior,col="red",add=TRUE)
legend(0.06, 80, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- och PriorfÃ¶rdelning")
dens(prior,col="red",add=TRUE)
legend(0.06, 80, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
legend(0.06, 70, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
dens(posterior,col="black", main = "Posterior- och PriorfÃ¶rdelning")
dens(prior,col="red",add=TRUE)
legend(0.06, 70, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
valdata <- read.csv2("C:/Users/Jakob/Desktop/Bayesian statistics/valdata.csv")
val_andel_mp <- valdata[1:12,10]/100
alpha <- 8.389154
beta <- 112.6174
prior <- rbeta(n = 1e4, alpha,beta, ncp=0)
dens(prior,main = "PriorfÃ¶rdelning beta(8.39,112.62)")
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- och PriorfÃ¶rdelning")
dens(prior,col="red",add=TRUE)
legend(0.06, 70, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
mean(posterior)
mean(prior)
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)
R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.
R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.
Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
[Workspace loaded from C:/Users/Jakob/Desktop/Bayesian statistics/.RData]
