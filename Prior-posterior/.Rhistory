prob_toolittle <- 1 - (odds_toolittle / (1+odds_toolittle))
p_aboutright <- prob_toolittle - prob_toomuch
odds_toomuch_vs_aboutright <- prob_toomuch/p_aboutright
odds_toomuch_vs_aboutright
require(foreign)
require(ggplot2)
require(MASS)
require(Hmisc)
require(reshape2)
load("C:/Users/Jakob/Desktop/KomplexaData/Lab1/Fattigdom.Rda")
fattig <- Fattigdom
ordered_model <- polr(WVS.poverty ~ WVS.religion + WVS.degree + WVS.age + WVS.gender, data = fattig, Hess=TRUE, method="logistic")
ln_odds_toomuch <- (2.3985890-ordered_model$coefficients[1]*1 - ordered_model$coefficients[2]*1 -
ordered_model$coefficients[3]*40 - ordered_model$coefficients[4]*1)
odds_toomuch <- exp(ln_odds_toomuch)
prob_toomuch <- 1 - (odds_toomuch / (1+odds_toomuch))
prob_toomuch
ln_odds_toolittle <- (0.6618151-ordered_model$coefficients[1]*1 - ordered_model$coefficients[2]*1 -
ordered_model$coefficients[3]*40 - ordered_model$coefficients[4]*1)
odds_toolittle <- exp(ln_odds_toolittle)
prob_toolittle <- 1 - (odds_toolittle / (1+odds_toolittle))
p_aboutright <- prob_toolittle - prob_toomuch
prob_toolittle
odds_toolittle
ln_odds_toolittle
ln_odds_toolittle <- (0.6618151-ordered_model$coefficients[1]*1 - ordered_model$coefficients[2]*1 -
ordered_model$coefficients[3]*40 - ordered_model$coefficients[4]*1)
odds_toolittle <- exp(ln_odds_toolittle)
prob_toolittle <- 1 - (odds_toolittle / (1+odds_toolittle))
p_aboutright <- prob_toolittle - prob_toomuch
odds_toomuch_vs_aboutright <- prob_toomuch/p_aboutright
ln_odds_toolittle
ln_odds_toolittle <- (0.6618151-ordered_model$coefficients[1]*1 - ordered_model$coefficients[2]*1 -
ordered_model$coefficients[3]*40 - ordered_model$coefficients[4]*1)
odds_toolittle <- exp(ln_odds_toolittle)
odds_toolittle
prob_toolittle
prob_toolittle
odds_toomuch_vs_aboutright
my2_xbeta <- (2.3985890-ordered_model$coefficients[1]*1 - ordered_model$coefficients[2]*1 -
ordered_model$coefficients[3]*40 - ordered_model$coefficients[4]*1)
my1_xbeta <- (0.6618151-ordered_model$coefficients[1]*1 - ordered_model$coefficients[2]*1 -
ordered_model$coefficients[3]*40 - ordered_model$coefficients[4]*1)
p_2<-plogis(my2_xbeta) - plogis(my1_xbeta)
p_3<- (1 - plogis(my2_xbeta))
p_3/p_2
p_3
p_2
### Uppgift 4 ###
#a)
my <- 100
a <- 130
sd <- (a-my)/qnorm(0.97)
iq_data <- rnorm(n = 10000, mean = my, sd = sd)
highiq_index <- iq_data>=120
highiq_data <- iq_data[highiq_index]
hist(highiq_data,probability = TRUE, main = "Fördelning av IQ >= 120")
require(rethinking)
valdata <- read.csv2("C:/Users/Jakob/Desktop/Bayesian statistics/valdata.csv")
alpha <- 8.389154
beta <- 112.6174
prior <- rbeta(n = 1e4, alpha,beta, ncp=0)
val_andel_mp <- valdata[1:12,10]/100
dens(prior,main = "Priorfördelning beta(8.39,112.62)")
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- och Priorfördelning")
dens(prior,col="red",add=TRUE)
legend(0.06, 70, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
mean(prior)
p_grid <- seq( from=0 , to=1 , length.out=1000 ) # grid av v?rden
# Allm?n Beta prior, BW, se f?rel?sningsslides
prior <- dbeta(p_grid, alpha, beta, ncp = 0, log = FALSE)
mean(posterior)
likelihood <- dbinom( round(sumxi) , size=n , prob=p_grid )
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior <- posterior / sum(posterior) # g?r posteriorn till en t?thet
# R code 3.3
samples_grid <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # dra v?rden fr?n posteriorn
# R code 3.4
plot( samples_grid ) # plotta v?rdena
dens(samples_grid, main = "Posteriorfördelning med grid approximation")
# R code 2.6, tag fram posteriorf?rdelningen med kvadratisk approximation
KA <- map(
alist(
w ~ dbinom(1612,p) , # binomial likelihood
p ~ dbeta(8.389154,112.6174) # beta prior
) ,
data=list(w=77) )
# display summary of quadratic approximation
precis( KA , digits=5)
# Plotta kvadratiska approximationen mot grid approximationen. Anv?nd medelv?rde och st.avv. fr?n funktion precis.
samplesQ <- rnorm(1e4,0.04875,0.00517)
#Black = gridapprox, Red = kvadrat approx
dens(samples_grid,type="l",col="black", main = "Posteriorfördelning med approximation")
dens(samplesQ,type="l",col="red",add=TRUE)
legend(0.055, 80, legend = c("Grid approximation", "Kvadrat approximation"), fill=c("black", "red"), cex = 0.8)
dens(samples_grid,type="l",col="black", main = "Posteriorfördelning med gridapproximation")
dens(posterior,type="l",col="red",add=TRUE)
legend(0.055, 80, legend = c("Grid approximation", "Posterior"), fill=c("black", "red"), cex = 0.8)
dens(samplesQ,type="l",col="black", main = "Posteriorfördelning med kvadrat approximation")
dens(posterior,type="l",col="red",add=TRUE)
legend(0.053, 75, legend = c("Kvadrat approximation", "Posterior"), fill=c("black", "red"), cex = 0.8)
mean(samples_grid)
sd(samples_grid)
#f)
posterior_PI <- rbeta(1e4,alpha,beta,ncp = 0)
PI( posterior_PI , prob=0.909 )
#g)
odds <- samplesQ / (1 - samplesQ)
dens(odds, main="Fördelning av odds för posteriorfördelningen")
data(chickwts)
soybeans_index <- chickwts$feed == "soybean"
meatmeal_index <- chickwts$feed == "meatmeal"
soybean_data <- chickwts[soybeans_index,1:2]
meatmeal_data <- chickwts[meatmeal_index,1:2]
ejsoy_ejmeat <-chickwts[!soybeans_index&!meatmeal_index,1:2]
#a)
Stavv <- sd(soybean_data[,1])
PriorMu <- mean(ejsoy_ejmeat[,1])
PriorStavv <- sd(ejsoy_ejmeat[,1])
flist <- alist(
weight ~ dnorm(mu, Stavv) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu , PriorStavv ) # normalf?rdelad prior
)
resNormal <- map(flist, data=soybean_data)
precis(resNormal)
samples_2a <- rnorm(1e4, 246.85, 14.27)
dens(samples_2a, type="l",col="black", main = "Posterior för kycklingar som ätit soybeans")
#b)
Stavv_b <- sd(meatmeal_data[,1])
PriorMu_b <- mean(ejsoy_ejmeat[,1])
PriorStavv_b <- sd(ejsoy_ejmeat[,1])
flist_b <- alist(
weight ~ dnorm(mu, Stavv_b) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu_b , PriorStavv_b ) # normalf?rdelad prior
)
resNormal_b <- map(flist_b, data=meatmeal_data)
precis(resNormal_b)
samples_2b <- rnorm(1e4, 276.2, 19.09)
dens(samples_2b, type="l",col="black",main = "Posterior för kycklingar som ätit meatmeal")
#Plotta a och b i samma
#Lägre medelvärdes vikt och högre varians i meatmeal kycklingar än soybean kycklingar
dens(samples_2a, type="l",col="black", main = "Fördelning av kycklingar ")
dens(samples_2b, type="l",col="red",add=TRUE)
require(rethinking)
valdata <- read.csv2("C:/Users/Jakob/Desktop/Bayesian statistics/Lab1/valdata.csv")
val_andel_mp <- valdata[1:12,10]/100
alpha <- 8.389154
beta <- 112.6174
View(valdata)
#b)
#posterior hyperparameters
#alhpa + sum xi, beta + n - sum xi
0.048*1612
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- och Priorfördelning")
dens(prior,col="red",add=TRUE)w
dens(prior,col="red",add=TRUE)
legend(0.06, 70, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
prior <- rbeta(n = 1e4, alpha,beta, ncp=0)
dens(prior,main = "Priorfördelning beta(8.39,112.62)")
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- och Priorfördelning")
dens(prior,col="red",add=TRUE)
legend(0.06, 70, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
mean(posterior)
mean(prior)
n <- 1612
sumxi <- 77.376
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- och Priorfördelning")
dens(prior,col="red",add=TRUE)
legend(0.06, 70, legend = c("Posterior", "Prior"), fill=c("black", "red"), cex = 0.8)
p_grid <- seq( from=0 , to=1 , length.out=1000 ) # grid av v?rden
# Allm?n Beta prior, BW, se f?rel?sningsslides
prior <- dbeta(p_grid, alpha, beta, ncp = 0, log = FALSE)
likelihood <- dbinom( round(sumxi) , size=n , prob=p_grid )
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior <- posterior / sum(posterior) # g?r posteriorn till en t?thet
# R code 3.3
samples_grid <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # dra v?rden fr?n posteriorn
# R code 3.4
plot( samples_grid ) # plotta v?rdena
dens(samples_grid, main = "Posteriorfördelning med grid approximation")
p_grid <- seq( from=0 , to=1 , length.out=100000 ) # grid av v?rden
# Allm?n Beta prior, BW, se f?rel?sningsslides
prior <- dbeta(p_grid, alpha, beta, ncp = 0, log = FALSE)
likelihood <- dbinom( round(sumxi) , size=n , prob=p_grid )
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior <- posterior / sum(posterior) # g?r posteriorn till en t?thet
# R code 3.3
samples_grid <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # dra v?rden fr?n posteriorn
# R code 3.4
plot( samples_grid ) # plotta v?rdena
dens(samples_grid, main = "Posteriorfördelning med grid approximation")
p_grid <- seq( from=-1 , to=1 , length.out=1000 ) # grid av v?rden
# Allm?n Beta prior
prior <- dbeta(p_grid, alpha, beta, ncp = 0, log = FALSE)
likelihood <- dbinom( round(sumxi) , size=n , prob=p_grid )
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior <- posterior / sum(posterior) # g?r posteriorn till en t?thet
p_grid <- seq( from=0 , to=1 , length.out=1000 ) # grid av v?rden
# Allm?n Beta prior
prior <- dbeta(p_grid, alpha, beta, ncp = 0, log = FALSE)
likelihood <- dbinom( round(sumxi) , size=n , prob=p_grid )
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior <- posterior / sum(posterior) # g?r posteriorn till en t?thet
#Posterior
samples_grid <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # dra v?rden fr?n posteriorn
plot( samples_grid ) # plotta v?rdena
dens(samples_grid, main = "Posteriorfördelning med grid approximation")
# R code 2.6, tag fram posteriorf?rdelningen med kvadratisk approximation
KA <- map(
alist(
w ~ dbinom(1612,p) , # binomial likelihood
p ~ dbeta(8.389154,112.6174) # beta prior
) ,
data=list(w=77) )
# display summary of quadratic approximation
precis( KA , digits=5)
# Plotta kvadratiska approximationen mot grid approximationen. Anv?nd medelv?rde och st.avv. fr?n funktion precis.
samplesQ <- rnorm(1e4,0.04875,0.00517)
#Black = gridapprox, Red = kvadrat approx
dens(samples_grid,type="l",col="black", main = "Posteriorfördelning med approximation")
dens(samplesQ,type="l",col="red",add=TRUE)
legend(0.055, 80, legend = c("Grid approximation", "Kvadrat approximation"), fill=c("black", "red"), cex = 0.8)
posterior <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
dens(posterior,col="black", main = "Posterior- och Priorfördelning")
#Posterior
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior
#Posterior till täthet
posterior <- likelihood * prior # posterior prop mot likelihood*prior
posterior <- posterior / sum(posterior) # g?r posteriorn till en t?thet
#Posterior
samples_grid <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # dra v?rden fr?n posteriorn
list(w=77)
flist <- alist( w ~ dbinom(1612,p) ,
p ~ dbeta(8.389154,112.6174)
)
KA <- map(flist, data=list(w=77))
# display summary of quadratic approximation
precis( KA , digits=5)
#f)
posterior_PI <- rbeta(1e4,alpha,beta,ncp = 0)
PI( posterior_PI , prob=0.909 )
#f)
posterior_PI <- rbeta(n = 1e4, alpha + sumxi, beta + n - sumxi, ncp = 0)
PI( posterior_PI , prob=0.909 )
samplesQ
#g)
odds <- samplesQ / (1 - samplesQ)
dens(odds, main="Fördelning av odds för posteriorfördelningen")
data(chickwts)
soybeans_index <- chickwts$feed == "soybean"
meatmeal_index <- chickwts$feed == "meatmeal"
soybean_data <- chickwts[soybeans_index,1:2]
meatmeal_data <- chickwts[meatmeal_index,1:2]
ejsoy_ejmeat <-chickwts[!soybeans_index&!meatmeal_index,1:2]
PI( posterior_PI , prob=0.909 )
data(chickwts)
soybeans_index <- chickwts$feed == "soybean"
meatmeal_index <- chickwts$feed == "meatmeal"
soybean_data <- chickwts[soybeans_index,1:2]
meatmeal_data <- chickwts[meatmeal_index,1:2]
ejsoy_ejmeat <-chickwts[!soybeans_index&!meatmeal_index,1:2]
#a)
Stavv <- sd(soybean_data[,1])
PriorMu <- mean(ejsoy_ejmeat[,1])
PriorStavv <- sd(ejsoy_ejmeat[,1])
flist <- alist(
weight ~ dnorm(mu, Stavv) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu , PriorStavv ) # normalf?rdelad prior
)
resNormal <- map(flist, data=soybean_data)
precis(resNormal)
#Plotta a och b i samma
#Lägre medelvärdes vikt och högre varians i meatmeal kycklingar än soybean kycklingar
dens(samples_2a, type="l",col="black", main = "Fördelning av kycklingar ")
dens(samples_2b, type="l",col="red",add=TRUE)
legend(260, 0.028, legend = c("Soybeans", "Meatmeal"), fill=c("black", "red"), cex = 0.8)
Stavv <- sd(soybean_data[,1])
PriorMu <- mean(ejsoy_ejmeat[,1])
PriorStavv <- sd(ejsoy_ejmeat[,1])
flist <- alist(
weight ~ dnorm(mu, Stavv) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu , PriorStavv ) # normalf?rdelad prior
)
resNormal <- map(flist, data=soybean_data)
precis(resNormal)
samples_2a <- rnorm(1e4, 246.85, 14.27)
dens(samples_2a, type="l",col="black", main = "Posterior för kycklingar som ätit soybeans")
#b)
#Modellera meatmeal kycklingars vikt
#Känds standaravikelse om meatmeal kycklingar
#Prior om mu och sd från kycklingar som ej rä soy eller meat
Stavv_b <- sd(meatmeal_data[,1])
PriorMu_b <- mean(ejsoy_ejmeat[,1])
PriorStavv_b <- sd(ejsoy_ejmeat[,1])
flist_b <- alist(
weight ~ dnorm(mu, Stavv_b) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu_b , PriorStavv_b ) # normalf?rdelad prior
)
resNormal_b <- map(flist_b, data=meatmeal_data)
precis(resNormal_b)
samples_2b <- rnorm(1e4, 276.2, 19.09)
dens(samples_2b, type="l",col="black",main = "Posterior för kycklingar som ätit meatmeal")
#Plotta a och b i samma
#Lägre medelvärdes vikt och högre varians i meatmeal kycklingar än soybean kycklingar
dens(samples_2a, type="l",col="black", main = "Fördelning av kycklingar ")
dens(samples_2b, type="l",col="red",add=TRUE)
#
sum( samples_2b > samples_2a) / 1e4
require(rethinking)
load("C:/Users/Jakob/Desktop/Bayesian statistics/lab2/Data_Moment2.RData")
require(rethinking)
load("C:/Users/Jakob/Desktop/Bayesian statistics/lab2/Data_Moment2.RData")
X <- as.data.frame(X)
set.seed(970922);y <- rnorm(n,A,B)
#a)
#Samplar från priorfördelningen för y
sampleMu <- rnorm(1e4,3,10)
sampleLogSigma <- rnorm(1e4,0,1)
require(rethinking)
load("C:/Users/Jakob/Desktop/Bayesian statistics/lab2/Data_Moment2.RData")
X <- as.data.frame(X)
set.seed(970922);y <- rnorm(n,A,B)
#a)
#Samplar från priorfördelningen för y
sampleMu <- rnorm(1e4,3,10)
sampleLogSigma <- rnorm(1e4,0,1)
sample_y <- rnorm(1e4,sampleMu,exp(sampleLogSigma))
dens(sample_y, main = "Priorfördelning för y", xlim = c(-50,50))
mean(sample_y)
flist <- alist(
y/1000 ~ dnorm(mu, exp(logsigma)) , # likelihood fr?n normalf?rdelning, liter per mil
mu ~ dnorm( 3 , 10 ) , # normalf?rdelad prior
logsigma ~ dnorm ( 0 , 1 )
)
resNormal_logsigma <- map(flist, data=X)
precis(resNormal_logsigma)
flist <- alist(
y/1000 ~ dnorm(mu, exp(logsigma)) , # likelihood fr?n normalf?rdelning, liter per mil
mu ~ dnorm( 3 , 10 ) , # normalf?rdelad prior
logsigma ~ dnorm ( 0 , 1 )
)
resNormal_logsigma <- map(flist, data=X)
precis(resNormal_logsigma)
postSamples_logsigma <- extract.samples(resNormal_logsigma , n=1e4) # posterior samples
exp(postSamples_logsigma)
exp(postSamples_logsigma$logsigma)
precis(exp(postSamples_logsigma$logsigma))
kredintervall_sigma <-precis(exp(postSamples_logsigma$logsigma))
#Plottar logsigma priorfördelningen mot logsigma posteriorfördelningen
dens(exp(sampleLogSigma), xlim = c(-1,8),ylim = c(0,3.8), main = "Sigma fördelning")
dens(exp(postSamples_logsigma[,2]),col="red",add=TRUE)
legend("topright", legend = c("Prior logsigma", "Posterior logsigma"), fill=c("black", "red"), cex = 0.8)
precis(resNormal_logsigma,prob=0.909)
postSamples_logsigma$sigma <- exp(postSamples_logsigma$logsigma)
Kovar <-cov(postSamples_logsigma[,c(1,3)])
cov2cor(Kovar)
precis(resNormal_logsigma,prob=0.909)
postSamples_logsigma$sigma <- exp(postSamples_logsigma$logsigma)
postSamples_logsigma$sigma
Kovar <-cov(postSamples_logsigma[,c(1,3)])
cov2cor(Kovar)
precis(exp(postSamples_logsigma$logsigma))
#Kan inte bara antilogga i precis, måste extracta och räkna om
#för att få kredibilitetsintervall för sigma inte logsigma
kredintervall_sigma <-precis(exp(postSamples_logsigma$logsigma),prob=0.909)
kredintervall_sigma
precis(resNormal_logsigma,prob=0.909)
postSamples_logsigma$sigma <- exp(postSamples_logsigma$logsigma)
Kovar <-cov(postSamples_logsigma[,c(1,3)])
cov2cor(Kovar)
yPred_1d <- rnorm(1e4,postSamples_logsigma[,1],exp(postSamples_logsigma[,2]))
dens(y/1000, xlim = c(-2,8), ylim = c(0,0.5), main="Posterior fördelning")
dens(yPred_1d,type="l",col="red",add=TRUE)
dens(sample_y, col="blue",add=TRUE)
legend("topright", legend = c("true y", "pred y", "prior y"), fill=c("black", "red","blue"), cex = 0.8)
f_sigma <- rchisq(1e4,nrow(X) - 1)
sigma2 <- ( (nrow(X) - 1) * var(y/1000) ) / f_sigma
mu_sigma2 <- rnorm(n = 1e4, mean(y/1000), sqrt(sigma2/nrow(X)))
#Plottar sigma2s posteriorfördelning med unif prior mot normalprior
dens(sqrt(sigma2), main="Posteriorfördelning sigma")
dens(exp(postSamples_logsigma[,2]),col="red",add=TRUE)
legend("topright",inset=.05, legend = c("Uniform prior", "Normal prior"), fill=c("black", "red","blue"), cex = 0.8)
#Plottar mu|sigma2s fördelning med unif prior mot normalprior
dens(mu_sigma2, main="Betingad posterior mu")
dens(postSamples_logsigma[,1],type="l",col="red",add=TRUE)
legend("topright",inset=.05, legend = c("Uniform prior", "Normal prior"), fill=c("black", "red","blue"), cex = 0.8)
#a)
data <- data.frame(y/1000,scale(X[,1:4]),X[,5:6])
colnames(data) <- c("y","area","antal_rum","avgift","trappor","cityyes","sydyes")
cor(data)
flist <- alist(
y ~ dnorm(mu, exp(logsigma)) , # likelihood fr?n normalf?rdelning, liter per mil
mu <- b0 + b1*area , # hur mu ?r l?nkad till f?rklaringsvariabler.
b0 ~ dnorm( 3 , 10 ) , # normalf?rdelad prior f?r intercept
b1 ~ dnorm( 0 , 10 ) ,
logsigma ~ dnorm ( 0, 1 )
)
resNormal <- map(flist, data=data)
precis(resNormal,prob=0.909)
postSamples_2a <- extract.samples(resNormal , n=1e4)
xSeq <- seq(from=min(data$area),to=max(data$area),by=0.01)
plot( data$y ~ data$area ,  col=col.alpha(rangi2,0.5) , main = "95.2% Kredibilitetsband")
# 90.9 % and 95.2 % Kredibilitetsintervall f?r mu f?r bilar mellan 800 och 2000 kg
mu.ci <- sapply( xSeq , function(x) PI( postSamples_2a[,1] + postSamples_2a[,2]*x , prob=0.952) )
shade( mu.ci , xSeq)
precis(resNormal,prob=0.909)
sim.y <- matrix(0,nrow=1e4,ncol=length(xSeq))
sigma <- exp(matrix(postSamples_2a[,3],nrow=1000,ncol=1))
for ( i in 1:length(xSeq) ){
mu <- postSamples_2a[,1] + postSamples_2a[,2]*xSeq[i]
sim.y[,i] <- rnorm(1e4,mu,sigma)
}
y.PI <- apply( sim.y , 2 , PI , prob=0.909 )
# plot raw data
plot( data$y ~ data$area , col=col.alpha(rangi2,0.5) , main = "90.9% Prediktionsintervall")
# draw MAP line
abline( a=coef(resNormal)["b0"] , b=coef(resNormal)["b1"] )
# draw PI region for simulated kilometres per litre (simulated y values)
shade( y.PI , xSeq )
#d)
RjSamples <- extract.samples(resNormal , n=1e4)
SSR_sample <- rep(NA, nrow(RjSamples))
SSE_sample <- rep(NA, nrow(RjSamples))
for (j in 1:nrow(RjSamples)) {
SSR <- rep(NA, length(data$area))
SSE <- rep(NA, length(data$area))
for (i in 1:length(data$area)) {
mu_i <- RjSamples[j,1] + RjSamples[j,2] * data$area[i]
SSR[i] <- (mu_i - mean(data$y))^2
SSE[i] <- (data$y[i] - mu_i)^2
}
SSR_sample[j] <- sum(SSR)
SSE_sample[j] <- sum(SSE)
}
R2_bayes <- SSR_sample / (SSR_sample + SSE_sample)
dens(R2_bayes, main = "Fördelning av Bayesian R^2")
mean(R2_bayes)
sd(R2_bayes)
flist <- alist(
y ~ dnorm(mu, exp(logsigma)) , # likelihood fr?n normalf?rdelning, liter per mil
mu <- b0 + b1*area + b2*antal_rum + b3*avgift + b4*trappor + b5*cityyes + b6*sydyes, # hur mu ?r l?nkad till f?rklaringsvariabler.
b0 ~ dnorm( 3 , 10 ) , # normalf?rdelad prior f?r intercept
c(b1,b2,b3,b4) ~ dnorm( 0 , 10 ) ,
c(b5,b6) ~ dnorm( 0 , 10 ) ,
logsigma ~ dnorm ( 0, 1 )
)
resNormal <- map(flist, data=data)
postSamples <- extract.samples(resNormal , n=1e6)
Odds <- matrix(NA, ncol = 6, nrow = 1)
colnames(Odds) <- c("b1","b2","b3","b4","b5","b6")
for (i in 1:6) {
ProbNegEff <- sum(postSamples[,i+1] < 0)/1e6
ProbPosEff <- 1 - ProbNegEff
Odds[,i] <- ProbNegEff/ProbPosEff
}
Odds
#c)
postSamples <- extract.samples(resNormal , n=1e4)
mu_ij <- matrix(NA,ncol = length(data$y), nrow = nrow(postSamples))
for (i in 1:nrow(postSamples)) {
for (j in 1:length(data$y)) {
mu_ij[i,j] <- (postSamples[i,1] + postSamples[i,2] * data$area[j] + postSamples[i,3] * data$antal_rum[j]
+ postSamples[i,4] * data$avgift[j] + postSamples[i,5] * data$trappor[j]
+ postSamples[i,6] * data$cityyes[j] + postSamples[i,7] * data$sydyes[j])
}
}
pred <- matrix(NA, ncol = length(data$y), nrow = nrow(postSamples))
for (i in 1:length(data$y)) {
pred[,i] <- rnorm(n = 1e3, mean = mu_ij[,i], sd = exp(postSamples$logsigma))
}
pred_matrix <- matrix(pred, ncol=1)
dens(pred_matrix, main = "Posteriorförldening")
dens(yPred_1d,type="l",col="blue",add=TRUE)
dens(data$y,add=TRUE,col="red")
legend("topright", legend = c("Pred med 6 xvar", "Pred med 0 xvar", "Data"), fill=c("black", "red","blue"), cex = 0.8)
require(rethinking)
load("C:/Users/Jakob/Desktop/Bayesian statistics/lab2/Data_Moment2.RData")
X <- as.data.frame(X)
set.seed(970922);y <- rnorm(n,A,B)
data <- data.frame(y/1000,scale(X[,1:4]),X[,5:6])
colnames(data) <- c("y","area","antal_rum","avgift","trappor","cityyes","sydyes")
require(rethinking)
data(chickwts)
soybeans_index <- chickwts$feed == "soybean"
meatmeal_index <- chickwts$feed == "meatmeal"
soybean_data <- chickwts[soybeans_index,1:2]
meatmeal_data <- chickwts[meatmeal_index,1:2]
ejsoy_ejmeat <-chickwts[!soybeans_index&!meatmeal_index,1:2]
Stavv <- sd(soybean_data[,1])
PriorMu <- mean(ejsoy_ejmeat[,1])
PriorStavv <- sd(ejsoy_ejmeat[,1])
flist <- alist(
weight ~ dnorm(mu, Stavv) , # likelihood fr?n normalf?rdelning
mu ~ dnorm( PriorMu , PriorStavv ) # normalf?rdelad prior
)
resNormal <- map(flist, data=soybean_data)
#Sannolikheten för att medelvärdes vikten för kycklingar som ätit
#Meatmeal är större än medelvärdes vikten för kycklingar
#som ätit soybeans.
sum( samples_2b > samples_2a) / 1e4
precis(resNormal_b)
